<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Attacker Module &mdash; easyjailbreak 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=92fd9be5" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=2389946f"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Constraint Module" href="constraint.html" />
    <link rel="prev" title="Attacker" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            easyjailbreak
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Attacker Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#autodan-liu-2023">AutoDAN_Liu_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#autodan-class">AutoDAN Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cipher-yuan-2023">Cipher_Yuan_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cipher-class">Cipher Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepinception-li-2023">DeepInception_Li_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepinception-class">DeepInception Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#gcg-zou-2023">GCG_Zou_2023</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gptfuzzer-yu-2023">Gptfuzzer_yu_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gptfuzzer-class">GPTFuzzer Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ica-wei-2023">ICA_wei_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ica-class">ICA Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#jailbroken-wei-2023">Jailbroken_wei_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#jailbroken-class">Jailbroken Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multilingual-deng-2023">Multilingual_Deng_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multilingual-class">Multilingual Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pair-chao-2023">PAIR_chao_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#catastrophic-modules">Catastrophic Modules</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tap-mehrotra-2023">TAP_Mehrotra_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tree-of-attacks-recipe">‘Tree of Attacks’ Recipe</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#renellm-ding-2023">ReNeLLM_ding_2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#renellm-class">ReNeLLM class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="constraint.html">Constraint Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metric Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluator.html">Evaluator Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="Seed.html">Seed Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="Selector.html">Selector Module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">easyjailbreak</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Attacker Module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/attacker.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="attacker-module">
<h1>Attacker Module<a class="headerlink" href="#attacker-module" title="Permalink to this heading"></a></h1>
<p>This section of documentation describes the submodules in easyjailbreak.attacker. The class here is used to initialize a method proposed in the paper for model jailbreaking</p>
<section id="autodan-liu-2023">
<h2>AutoDAN_Liu_2023<a class="headerlink" href="#autodan-liu-2023" title="Permalink to this heading"></a></h2>
<section id="autodan-class">
<h3>AutoDAN Class<a class="headerlink" href="#autodan-class" title="Permalink to this heading"></a></h3>
<p>This Class achieves a jailbreak method describe in the paper below.
This part of code is based on the code from the paper.</p>
<p>Paper title: AUTODAN: GENERATING STEALTHY JAILBREAK PROMPTS ON ALIGNED LARGE LANGUAGE MODELS</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/abs/2310.04451">https://arxiv.org/abs/2310.04451</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/SheltonLiu-N/AutoDAN.git">https://github.com/SheltonLiu-N/AutoDAN.git</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.AutoDAN_Liu_2023.</span></span><span class="sig-name descname"><span class="pre">AutoDAN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreakDatasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_jailbreak</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_reject</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iteration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda:0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sentence_level_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_dict_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_elites</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crossover_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mutation_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_points</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'llama2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_memory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pattern_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>AutoDAN is a class for conducting jailbreak attacks on language models.
AutoDAN can automatically generate stealthy jailbreak prompts by hierarchical genetic algorithm.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Main loop for the attack process, iterate through jailbreakDatasets.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">construct_momentum_word_dictionary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">individuals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_list</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>calculate momentum with score_list to maintain a momentum word_dict</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">evaluate_candidate_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_manager</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Calculate current candidate prompts scores of sample, get the currently best prompt and the corresponding response.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_score_autodan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conv_template</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">instruction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_controls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Convert all test_controls to token ids and find the max length</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_score_autodan_low_memory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conv_template</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">instruction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_controls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Convert all test_controls to token ids and find the max length when memory is low</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">replace_with_synonyms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>replace words in sentence with synonyms</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">roulette_wheel_selection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_selected</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>apply roulette_wheel_selection on data_list</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Perform the AutoDAN-HGA algorithm on a single query.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>update jailbreak state</p>
</dd></dl>

</dd></dl>

</section>
<section id="cipher-yuan-2023">
<h2>Cipher_Yuan_2023<a class="headerlink" href="#cipher-yuan-2023" title="Permalink to this heading"></a></h2>
<section id="cipher-class">
<h3>Cipher Class<a class="headerlink" href="#cipher-class" title="Permalink to this heading"></a></h3>
<p>This Class enables humans to chat with LLMs through cipher prompts topped with
system role descriptions and few-shot enciphered demonstrations.</p>
<p>Paper title：GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</p>
<p>arXiv Link: <a class="reference external" href="https://arxiv.org/pdf/2308.06463.pdf">https://arxiv.org/pdf/2308.06463.pdf</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/RobustNLP/CipherChat">https://github.com/RobustNLP/CipherChat</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.Cipher_Yuan_2023.</span></span><span class="sig-name descname"><span class="pre">Cipher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Jailbreak_Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Cipher is a class for conducting jailbreak attacks on language models. It integrates attack
strategies and policies to evaluate and exploit weaknesses in target language models.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using four cipher methods on the entire Jailbreak_Dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>Conduct four cipher attack_mehtods on a single source instance.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the Cipher based on the evaluation results of attack_results.</p>
</dd></dl>

</dd></dl>

</section>
<section id="deepinception-li-2023">
<h2>DeepInception_Li_2023<a class="headerlink" href="#deepinception-li-2023" title="Permalink to this heading"></a></h2>
<section id="deepinception-class">
<h3>DeepInception Class<a class="headerlink" href="#deepinception-class" title="Permalink to this heading"></a></h3>
<p>This class can easily hypnotize LLM to be a jailbreaker and unlock its
misusing risks.</p>
<p>Paper title: DeepInception: Hypnotize Large Language Model to Be Jailbreaker</p>
<p>arXiv Link: <a class="reference external" href="https://arxiv.org/pdf/2311.03191.pdf">https://arxiv.org/pdf/2311.03191.pdf</a></p>
<p>Source repository:  <a class="reference external" href="https://github.com/tmlr-group/DeepInception">https://github.com/tmlr-group/DeepInception</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.DeepInception_Li_2023.</span></span><span class="sig-name descname"><span class="pre">DeepInception</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Jailbreak_Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scene</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">character_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>DeepInception is a class for conducting jailbreak attacks on language models.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using provided prompts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>single_attack is a method for conducting jailbreak attacks on language models.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the Jailbroken based on the evaluation results of Datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Dataset</strong> – The Dataset that is attacked.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="gcg-zou-2023">
<h2>GCG_Zou_2023<a class="headerlink" href="#gcg-zou-2023" title="Permalink to this heading"></a></h2>
<p>Iteratively optimizes a specific section in the prompt using guidance from token gradients,
ensuring that the model produces the desired text.</p>
<p>Paper title: Universal and Transferable Adversarial Attacks on Aligned Language Models</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/abs/2307.15043">https://arxiv.org/abs/2307.15043</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/llm-attacks/llm-attacks/">https://github.com/llm-attacks/llm-attacks/</a></p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.GCG_Zou_2023.</span></span><span class="sig-name descname"><span class="pre">GCG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">WhiteBoxModelBase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ModelBase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreak_datasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreak_prompt_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_turb_sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batchsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_universal</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd><dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Abstract method for performing the attack.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Perform a single-instance attack, a common use case of the attack method. Returns a JailbreakDataset containing the attack results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>instance</strong> (<em>Instance</em>) – The instance to be attacked.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attacked dataset containing the modified instances.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>JailbreakDataset</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="gptfuzzer-yu-2023">
<h2>Gptfuzzer_yu_2023<a class="headerlink" href="#gptfuzzer-yu-2023" title="Permalink to this heading"></a></h2>
<section id="gptfuzzer-class">
<h3>GPTFuzzer Class<a class="headerlink" href="#gptfuzzer-class" title="Permalink to this heading"></a></h3>
<p>This Class achieves a jailbreak method describe in the paper below.
This part of code is based on the code from the paper.</p>
<p>Paper title: GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/pdf/2309.10253.pdf">https://arxiv.org/pdf/2309.10253.pdf</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/sherdencooper/GPTFuzz">https://github.com/sherdencooper/GPTFuzz</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.Gptfuzzer_yu_2023.</span></span><span class="sig-name descname"><span class="pre">GPTFuzzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreakDatasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">energy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_jailbreak</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_reject</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iteration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seeds_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">76</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>GPTFuzzer is a class for performing fuzzing attacks on LLM-based models.
It utilizes mutator and selection policies to generate jailbreak prompts,
aiming to find vulnerabilities in target models.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Main loop for the fuzzing process, repeatedly selecting, mutating, evaluating, and updating.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">is_stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Check if the stopping criteria for fuzzing are met.
:return bool: True if any stopping criteria is met, False otherwise.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>The current attack status is displayed</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Perform an attack using a single query.
:param ~Instance instance: The instance to be used in the attack. In gptfuzzer, the instance jailbreak_prompt is mutated by different methods.
:return: ~JailbreakDataset: The response from the mutated query.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the fuzzer based on the evaluation results of prompt nodes.
:param ~JailbreakDataset prompt_nodes: The prompt nodes that have been evaluated.</p>
</dd></dl>

</dd></dl>

</section>
<section id="ica-wei-2023">
<h2>ICA_wei_2023<a class="headerlink" href="#ica-wei-2023" title="Permalink to this heading"></a></h2>
<section id="ica-class">
<h3>ICA Class<a class="headerlink" href="#ica-class" title="Permalink to this heading"></a></h3>
<p>This Class executes the In-Context Attack algorithm described in the paper below.
This part of code is based on the paper.</p>
<p>Paper title: Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations
arXiv link: <a class="reference external" href="https://arxiv.org/pdf/2310.06387.pdf">https://arxiv.org/pdf/2310.06387.pdf</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.ICA_wei_2023.</span></span><span class="sig-name descname"><span class="pre">ICA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreakDatasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_jailbreak</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_reject</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iteration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">user_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pattern_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>In-Context Attack(ICA) crafts malicious contexts to guide models in generating harmful outputs.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Main loop for the attack process, iterate through jailbreakDatasets.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Conduct a single attack on sample with n-shot attack demonstrations.
Split the original jailbreak_prompt by roles and merge them into the current conversation_template as in-context demonstration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the attack.</p>
</dd></dl>

</dd></dl>

</section>
<section id="jailbroken-wei-2023">
<h2>Jailbroken_wei_2023<a class="headerlink" href="#jailbroken-wei-2023" title="Permalink to this heading"></a></h2>
<section id="jailbroken-class">
<h3>Jailbroken Class<a class="headerlink" href="#jailbroken-class" title="Permalink to this heading"></a></h3>
<p>Jailbroken utilized competing objectives and mismatched generalization
modes of LLMs to constructed 29 artificial jailbreak methods.</p>
<p>Paper title: Jailbroken: How Does LLM Safety Training Fail?</p>
<p>arXiv Link: <a class="reference external" href="https://arxiv.org/pdf/2307.02483.pdf">https://arxiv.org/pdf/2307.02483.pdf</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.Jailbroken_wei_2023.</span></span><span class="sig-name descname"><span class="pre">Jailbroken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Jailbreak_Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Implementation of Jailbroken Jailbreak Challenges in Large Language Models</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using provided prompts and mutations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>single attack process using provided prompts and mutation methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>instance</strong> – The Instance that is attacked.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the Jailbroken based on the evaluation results of Datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Dataset</strong> – The Dataset that is attacked.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="multilingual-deng-2023">
<h2>Multilingual_Deng_2023<a class="headerlink" href="#multilingual-deng-2023" title="Permalink to this heading"></a></h2>
<section id="multilingual-class">
<h3>Multilingual Class<a class="headerlink" href="#multilingual-class" title="Permalink to this heading"></a></h3>
<p>This Class translates harmful queries from English into nine non-English
languages with varying levels of resources, and in intentional scenarios,
malicious users deliberately combine malicious instructions with multilingual
prompts to attack LLMs.</p>
<p>Paper title: MULTILINGUAL JAILBREAK CHALLENGES IN LARGE LANGUAGE MODELS</p>
<p>arXiv Link: <a class="reference external" href="https://arxiv.org/pdf/2310.06474.pdf">https://arxiv.org/pdf/2310.06474.pdf</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs">https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.Multilingual_Deng_2023.</span></span><span class="sig-name descname"><span class="pre">Multilingual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Jailbreak_Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Multilingual is a class for conducting jailbreak attacks on language models.
It can translate harmful queries from English into nine non-English languages.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using Multilingual Jailbreak in Large Language Models.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>Execute the single attack process using provided prompts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">translate_to_en</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_lang</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Translate target response to English.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>update the state of the Jailbroken based on the evaluation results of Datasets.</p>
</dd></dl>

</dd></dl>

</section>
<section id="pair-chao-2023">
<h2>PAIR_chao_2023<a class="headerlink" href="#pair-chao-2023" title="Permalink to this heading"></a></h2>
<section id="catastrophic-modules">
<h3>Catastrophic Modules<a class="headerlink" href="#catastrophic-modules" title="Permalink to this heading"></a></h3>
<p>This Module achieves a jailbreak method describe in the paper below.
This part of code is based on the code from the paper.</p>
<p>Paper title: Jailbreaking Black Box Large Language Models in Twenty Queries</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/abs/2310.08419">https://arxiv.org/abs/2310.08419</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/patrickrchao/JailbreakingLLMs">https://github.com/patrickrchao/JailbreakingLLMs</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.PAIR_chao_2023.</span></span><span class="sig-name descname"><span class="pre">PAIR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreak_datasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">template_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_n_attack_attempts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">judge_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">judge_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_streams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_last_n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span></dt>
<dd><dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PAIR_attack_result.jsonl'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Abstract method for performing the attack.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Perform a single-instance attack, a common use case of the attack method. Returns a JailbreakDataset containing the attack results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>instance</strong> (<em>Instance</em>) – The instance to be attacked.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attacked dataset containing the modified instances.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>JailbreakDataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the ReNeLLM based on the evaluation results of Datasets.</p>
</dd></dl>

</dd></dl>

</section>
<section id="tap-mehrotra-2023">
<h2>TAP_Mehrotra_2023<a class="headerlink" href="#tap-mehrotra-2023" title="Permalink to this heading"></a></h2>
<section id="tree-of-attacks-recipe">
<h3>‘Tree of Attacks’ Recipe<a class="headerlink" href="#tree-of-attacks-recipe" title="Permalink to this heading"></a></h3>
<p>This module implements a jailbreak method describe in the paper below.
This part of code is based on the code from the paper.</p>
<p>Paper title: Tree of Attacks: Jailbreaking Black-Box LLMs Automatically</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/abs/2312.02119">https://arxiv.org/abs/2312.02119</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/RICommunity/TAP">https://github.com/RICommunity/TAP</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.TAP_Mehrotra_2023.</span></span><span class="sig-name descname"><span class="pre">TAP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">branching_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_last_n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_n_attack_attempts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">template_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attack_top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">judge_max_n_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">judge_temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Tree of Attack method, an extension of PAIR method. Use 4 phases:
1. Branching
2. Pruning: (phase 1)
3. Query and Access
4. Pruning: (phase 2)</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">easyjailbreak.attacker.TAP_Mehrotra_2023</span> <span class="kn">import</span> <span class="n">TAP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">easyjailbreak.models.huggingface_model</span> <span class="kn">import</span> <span class="n">from_pretrained</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">easyjailbreak.datasets.jailbreak_datasets</span> <span class="kn">import</span> <span class="n">JailbreakDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">easyjailbreak.datasets.Instance</span> <span class="kn">import</span> <span class="n">Instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attack_model</span> <span class="o">=</span> <span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path_1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_model</span> <span class="o">=</span> <span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eval_model</span>  <span class="o">=</span> <span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path_3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">JailbreakDataset</span><span class="p">(</span><span class="s1">&#39;AdvBench&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attacker</span> <span class="o">=</span> <span class="n">TAP</span><span class="p">(</span><span class="n">attack_model</span><span class="p">,</span> <span class="n">target_model</span><span class="p">,</span> <span class="n">eval_model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attacker</span><span class="o">.</span><span class="n">attack</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attacker</span><span class="o">.</span><span class="n">jailbreak_Dataset</span><span class="o">.</span><span class="n">save_to_jsonl</span><span class="p">(</span><span class="s2">&quot;./TAP_results.jsonl&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'TAP_attack_result.jsonl'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using provided prompts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>Conduct an attack for an instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>instance</strong> (<em>~Instance</em>) – The Instance that is attacked.</p>
</dd>
<dt class="field-even">Return ~JailbreakDataset<span class="colon">:</span></dt>
<dd class="field-even"><p>returns the attack result dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the ReNeLLM based on the evaluation results of Datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>~JailbreakDataset</strong> – processed dataset after an iteration</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="renellm-ding-2023">
<h2>ReNeLLM_ding_2023<a class="headerlink" href="#renellm-ding-2023" title="Permalink to this heading"></a></h2>
<section id="renellm-class">
<h3>ReNeLLM class<a class="headerlink" href="#renellm-class" title="Permalink to this heading"></a></h3>
<p>The implementation of our paper “A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily”.</p>
<p>Paper title: A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily</p>
<p>arXiv link: <a class="reference external" href="https://arxiv.org/pdf/2311.08268.pdf">https://arxiv.org/pdf/2311.08268.pdf</a></p>
<p>Source repository: <a class="reference external" href="https://github.com/NJUNLP/ReNeLLM">https://github.com/NJUNLP/ReNeLLM</a></p>
</section>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">easyjailbreak.attacker.ReNeLLM_ding_2023.</span></span><span class="sig-name descname"><span class="pre">ReNeLLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attack_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jailbreakDatasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evo_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>ReNeLLM is a class for conducting jailbreak attacks on language models.
It integrates attack strategies and policies to evaluate and exploit weaknesses in target language models.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attack</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Execute the attack process using provided prompts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Report the attack results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">single_attack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">instance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Instance</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">JailbreakDataset</span></span></span></dt>
<dd><p>Conduct an attack for an instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>instance</strong> (<em>~Instance</em>) – The Instance that is attacked.</p>
</dd>
<dt class="field-even">Return ~JailbreakDataset<span class="colon">:</span></dt>
<dd class="field-even"><p>returns the attack result dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">JailbreakDataset</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Update the state of the ReNeLLM based on the evaluation results of Datasets.</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Attacker" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="constraint.html" class="btn btn-neutral float-right" title="Constraint Module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, zwk.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>